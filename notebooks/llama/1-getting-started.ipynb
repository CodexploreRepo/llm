{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac959c4b-d7a9-4949-9c39-2ab46fbf82cd",
   "metadata": {},
   "source": [
    "# Lesson 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df1e2b-2079-4dee-84e9-77e13dd31e05",
   "metadata": {},
   "source": [
    "### Getting started with Llama 2\n",
    "\n",
    "**Update: Llama 3 was released on April 18 and this notebook has been updated to show how to use both Llama 3 and Llama 2 models hosted on Together.ai.**\n",
    "\n",
    "The code to call the Llama 2 models through the Together.ai hosted API service has been wrapped into a helper function called `llama`. You can take a look at this code if you like by opening the utils.py file using the File -> Open menu item above this notebook (the last optional lesson also covers the helper function in more detail).\n",
    "\n",
    "Note: To see how to run Llama 2 or 3 locally on your own computer, you can go to the last section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10075542-6019-40b6-b3c1-532383e4a6dd",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# import llama helper function\n",
    "from utils import llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a549fd-dd50-4ae1-a5d8-ce00fdc707a3",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# define the prompt\n",
    "prompt = \"Help me write a birthday card for my dear friend Andrew.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d46c4b-2926-44a9-9e25-befb6bd6648c",
   "metadata": {},
   "source": [
    "**Note:** LLMs can have different responses for the same prompt, which is why throughout the course, the responses you get might be slightly different than the ones in the lecture videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89f4c48-363d-4ddb-8f20-215bbd47004a",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course, I'd be happy to help you write a birthday card for your dear friend Andrew! Here are a few suggestions:\n",
      "\n",
      "1. Personalized Message: Start by writing a personalized message that speaks to your friendship with Andrew. You could mention a favorite memory or inside joke that only the two of you share.\n",
      "\n",
      "Example:\n",
      "\n",
      "\"Happy birthday to my favorite friend, Andrew! I can't believe it's been [X] years since we met. You've been there for me through thick and thin, and I'm so grateful for your friendship. Here's to another year of adventures and good times together! üéâ\"\n",
      "\n",
      "2. Funny Quote: If you want to add a bit of humor to your card, consider using a funny quote that relates to Andrew's personality or interests.\n",
      "\n",
      "Example:\n",
      "\n",
      "\"Happy birthday to the most awesome Andrew in the world! May your day be as epic as your beard and your love for [insert hobby or interest here] üòÇ\"\n",
      "\n",
      "3. Heartfelt Words: If you want to express your feelings in a more heartfelt way, try writing a message that speaks to the importance of Andrew in your life.\n",
      "\n",
      "Example:\n",
      "\n",
      "\"Andrew, you're more than just a friend to me. You're a constant source of support, laughter, and inspiration. I'm so grateful to have you in my life, and I can't wait to see what the next year brings for you. Happy birthday, my dear friend! ‚ù§Ô∏è\"\n",
      "\n",
      "4. Inside Joke: If you and Andrew share a special inside joke or reference, consider including it in your card. It will make the message more personal and meaningful to him.\n",
      "\n",
      "Example:\n",
      "\n",
      "\"Happy birthday to the one and only Andrew! May your day be as awesome as the time we [insert inside joke here] üòÇ\"\n",
      "\n",
      "Remember, the most important thing is to be sincere and genuine in your message. Write from the heart, and Andrew is sure to appreciate the thought and effort you put into the card.\n"
     ]
    }
   ],
   "source": [
    "# pass prompt to the llama function, store output as 'response' then print\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a573ca3f-9ffc-4f08-91eb-7e88d99d2f9f",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]Help me write a birthday card for my dear friend Andrew.[/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Help me write a birthday card for my dear friend Andrew.\"\n",
    "# Set verbose to True to see the full prompt that is passed to the model.\n",
    "# Start and End the instruction are surrounded by [INST] and [/INST] tags\n",
    "response = llama(prompt, verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c9bc9-9777-45bb-9e52-1cd99a42e716",
   "metadata": {},
   "source": [
    "### Chat vs. base models\n",
    "\n",
    "Ask model a simple question to demonstrate the different behavior of chat vs. base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37cc261-a9d5-486c-a0f1-7f0ce93f403e",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]What is the capital of France?[/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n"
     ]
    }
   ],
   "source": [
    "### chat model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"togethercomputer/llama-2-7b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d596d0-9469-4220-a03a-b50b0226776d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71bef6df-ce83-4be7-98a7-cd0c353c4188",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: togethercomputer/llama-2-7b\n"
     ]
    }
   ],
   "source": [
    "### base model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 add_inst=False, # since the foundation model didnt train to get the instruction tag, so set add_inst=False to avoid add instruction tag\n",
    "                 model=\"togethercomputer/llama-2-7b\") # foundation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf01a1-2c3e-4073-a4b7-546f5de0e5a1",
   "metadata": {},
   "source": [
    "Note how the prompt **does not** include the `[INST]` and `[/INST]` tags as `add_inst` was set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1941be3a-de66-4d08-808e-f93a0393f864",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10. What is the capital of Germany?\n",
      "11. What is the capital of Greece?\n",
      "12. What is the capital of Hungary?\n",
      "13. What is the capital of Iceland?\n",
      "14. What is the capital of India?\n",
      "15. What is the capital of Indonesia?\n",
      "16. What is the capital of Iran?\n",
      "17. What is the capital of Iraq?\n",
      "18. What is the capital of Ireland?\n",
      "19. What is the capital of Israel?\n",
      "20. What is the capital of Italy?\n",
      "21. What is the capital of Japan?\n",
      "22. What is the capital of Jordan?\n",
      "23. What is the capital of Kazakhstan?\n",
      "24. What is the capital of Kenya?\n",
      "25. What is the capital of Kuwait?\n",
      "26. What is the capital of Kyrgyzstan?\n",
      "27. What is the capital of Laos?\n",
      "28. What is the capital of Latvia?\n",
      "29. What is the capital of Lebanon?\n",
      "30. What is the capital of Lesotho?\n",
      "31. What is the capital of Liberia?\n",
      "32. What is the capital of Libya?\n",
      "33. What is the capital of Liechtenstein?\n",
      "34. What is the capital of Lithuania?\n",
      "35. What is the capital of Luxembourg?\n",
      "36. What is the capital of Macedonia?\n",
      "37. What is the capital of Mad\n"
     ]
    }
   ],
   "source": [
    "print(response[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236ad4e",
   "metadata": {
    "height": 30
   },
   "source": [
    "- Foundation model did not answer the question, but it returns similar questions to the original questions.\n",
    "    - Note: foundation model is not trained to receive the instruction tag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28242f9a-c36e-423e-af36-d2392c67ac4c",
   "metadata": {},
   "source": [
    "### Using Llama 3 chat models\n",
    "\n",
    "Together.ai supports both Llama 3 8b chat and Llama 3 70b chat models with the following names (case-insensitive):\n",
    "* meta-llama/Llama-3-8b-chat-hf\t\n",
    "* meta-llama/Llama-3-70b-chat-hf\n",
    "\n",
    "You can simply set the `model` parameter to one of the Llama 3 model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e3d0776-6f1d-49dc-a8eb-302a78e71b01",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: META-LLAMA/LLAMA-3-8B-CHAT-HF\n"
     ]
    }
   ],
   "source": [
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"META-LLAMA/LLAMA-3-8B-CHAT-HF\", \n",
    "                 add_inst=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65423187-e2dc-492a-86fa-e3431238a6d1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**\n",
      "**Answer:** Paris.\n",
      "\n",
      "**What is the capital of the United States?**\n",
      "**Answer:** Washington, D.C.\n",
      "\n",
      "**What is the capital of China?**\n",
      "**Answer:** Beijing.\n",
      "\n",
      "**What is the capital of Japan?**\n",
      "**Answer:** Tokyo.\n",
      "\n",
      "**What is the capital of India?**\n",
      "**Answer:** New Delhi.\n",
      "\n",
      "**What is the capital of Brazil?**\n",
      "**Answer:** Bras√≠lia.\n",
      "\n",
      "**What is the capital of Russia?**\n",
      "**Answer:** Moscow.\n",
      "\n",
      "**What is the capital of Australia?**\n",
      "**Answer:** Canberra.\n",
      "\n",
      "**What is the capital of South Africa?**\n",
      "**Answer:** Pretoria (administrative capital) and Cape Town (legislative capital).\n",
      "\n",
      "**What is the capital of Canada?**\n",
      "**Answer:** Ottawa.\n",
      "\n",
      "**What is the capital of Mexico?**\n",
      "**Answer:** Mexico City.\n",
      "\n",
      "**What is the capital of Germany?**\n",
      "**Answer:** Berlin.\n",
      "\n",
      "**What is the capital of Italy?**\n",
      "**Answer:** Rome.\n",
      "\n",
      "**What is the capital of Spain?**\n",
      "**Answer:** Madrid.\n",
      "\n",
      "**What is the capital of the United Kingdom?**\n",
      "**Answer:** London.\n",
      "\n",
      "**What is the capital of Sweden?**\n",
      "**Answer:** Stockholm.\n",
      "\n",
      "**What is the capital of Norway?**\n",
      "**Answer:** Oslo.\n",
      "\n",
      "**What is the capital of Denmark?**\n",
      "**Answer:** Copenhagen.\n",
      "\n",
      "**What is the capital of Finland?**\n",
      "**Answer:** Helsinki.\n",
      "\n",
      "**What is the capital of Poland?**\n",
      "**Answer:** Warsaw.\n",
      "\n",
      "**What is the capital of Greece?**\n",
      "**Answer:** Athens.\n",
      "\n",
      "**What is the capital of Turkey?**\n",
      "**Answer:** Ankara.\n",
      "\n",
      "**What is the capital of Egypt?**\n",
      "**Answer:** Cairo.\n",
      "\n",
      "**What is the capital of Israel?**\n",
      "**Answer:** Jerusalem.\n",
      "\n",
      "**What is the capital of South Korea?**\n",
      "**Answer:** Seoul.\n",
      "\n",
      "**What is the capital of North Korea?**\n",
      "**Answer:** Pyongyang.\n",
      "\n",
      "**What is the capital of Vietnam?**\n",
      "**Answer:** Hanoi.\n",
      "\n",
      "**What is the capital of Thailand?**\n",
      "**Answer:** Bangkok.\n",
      "\n",
      "**What is the capital of Indonesia?**\n",
      "**Answer:** Jakarta.\n",
      "\n",
      "**What is the capital of Malaysia?**\n",
      "**Answer:** Kuala Lumpur.\n",
      "\n",
      "**What is the capital of Singapore?**\n",
      "**Answer:** Singapore.\n",
      "\n",
      "**What is the capital of the Philippines?**\n",
      "**Answer:** Manila.\n",
      "\n",
      "**What is the capital of the United Arab Emirates?**\n",
      "**Answer:** Abu Dhabi.\n",
      "\n",
      "**What is the capital of Saudi Arabia?**\n",
      "**Answer:** Riyadh.\n",
      "\n",
      "**What is the capital of Iran?**\n",
      "**Answer:** Tehran.\n",
      "\n",
      "**What is the capital of Iraq?**\n",
      "**Answer:** Baghdad.\n",
      "\n",
      "**What is the capital of Afghanistan?**\n",
      "**Answer:** Kabul.\n",
      "\n",
      "**What is the capital of Pakistan?**\n",
      "**Answer:** Islamabad.\n",
      "\n",
      "**What is the capital of Bangladesh?**\n",
      "**Answer:** Dhaka.\n",
      "\n",
      "**What is the capital of Sri Lanka?**\n",
      "**Answer:** Colombo.\n",
      "\n",
      "**What is the capital of Myanmar (Burma)?**\n",
      "**Answer:** Naypyidaw.\n",
      "\n",
      "**What is the capital of Cambodia?**\n",
      "**Answer:** Phnom Penh.\n",
      "\n",
      "**What is the capital of Laos?**\n",
      "**Answer:** Vientiane.\n",
      "\n",
      "**What is the capital of Myanmar (Burma)?**\n",
      "**Answer:** Naypyidaw.\n",
      "\n",
      "**What is the capital of Nepal?**\n",
      "**Answer:** Kathmandu.\n",
      "\n",
      "**What is the capital of Bhutan?**\n",
      "**Answer:** Thimphu.\n",
      "\n",
      "**What is the capital of Mongolia?**\n",
      "**Answer:** Ulaanbaatar.\n",
      "\n",
      "**What is the capital of Kazakhstan?**\n",
      "**Answer:** Astana.\n",
      "\n",
      "**What is the capital of Uzbekistan?**\n",
      "**Answer:** Tashkent.\n",
      "\n",
      "**What is the capital of Turkmenistan?**\n",
      "**Answer:** Ashgabat.\n",
      "\n",
      "**What is the capital of Tajikistan?**\n",
      "**Answer:** Dushanbe.\n",
      "\n",
      "**What is the capital of Kyrgyzstan?**\n",
      "**Answer:** Bishkek.\n",
      "\n",
      "**What is the capital of Azerbaijan?**\n",
      "**Answer:** Baku.\n",
      "\n",
      "**What is the capital of Georgia?**\n",
      "**Answer:** Tbilisi.\n",
      "\n",
      "**What is the capital of Armenia?**\n",
      "**Answer:** Yerevan.\n",
      "\n",
      "**What is the capital of Belarus?**\n",
      "**Answer:** Minsk.\n",
      "\n",
      "**What is the capital of Ukraine?**\n",
      "**Answer:** Kiev.\n",
      "\n",
      "**What is the capital of Moldova?**\n",
      "**Answer:** Chi»ôinƒÉu.\n",
      "\n",
      "**What is the capital of Romania?**\n",
      "**Answer:** Bucharest.\n",
      "\n",
      "**What is the capital of Bulgaria?**\n",
      "**Answer:** Sofia.\n",
      "\n",
      "**What is the capital of Hungary?**\n",
      "**Answer:** Budapest.\n",
      "\n",
      "**What is the capital of Slovakia?**\n",
      "**Answer:** Bratislava.\n",
      "\n",
      "**What is the capital of the Czech Republic?**\n",
      "**Answer:** Prague.\n",
      "\n",
      "**What is the capital of Poland?**\n",
      "**Answer:** Warsaw.\n",
      "\n",
      "**What is the capital of Lithuania?**\n",
      "**Answer:** Vilnius.\n",
      "\n",
      "**What is the capital of Latvia?**\n",
      "**Answer:** Riga.\n",
      "\n",
      "**What is the capital\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9531475d-430f-4020-9784-1760eb79cbff",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]What is the capital of France?[/INST]\n",
      "\n",
      "model: META-LLAMA/LLAMA-3-70B-CHAT-HF\n",
      "A) Berlin B) Paris C) London D) Rome[/Q]\n",
      "[A]The correct answer is B) Paris. Paris is the capital and most populous city of France.[/A]\n",
      "\n",
      "[Q]What is the largest planet in our solar system?[/Q]\n",
      "[A]The largest planet in our solar system is Jupiter. It is the fifth planet from the Sun and is the largest of all the planets in terms of both mass and size. It has a diameter of approximately  a massive 142,984 kilometers (88,846 miles).[/A]\n",
      "\n",
      "[Q]What is the chemical symbol for gold?[/Q]\n",
      "[A]The chemical symbol for gold is Au. Gold is a chemical element with the atomic number 79 and the symbol comes from the Latin word for gold, \"Aurum\".[/A]\n",
      "\n",
      "[Q]Which of the following authors wrote the famous novel \"To Kill a Mockingbird\"?[/Q]\n",
      "[A]The correct answer is Harper Lee. Harper Lee wrote the Pulitzer Prize-winning novel \"To Kill a Mockingbird\", which was published in 1960 and has since become a classic of modern American literature.[/A]\n",
      "\n",
      "[Q]What is the smallest country in the world, both in terms of population and land area?[/Q]\n",
      "[A]The smallest country in the world, both in terms of population and land area, is the Vatican City. It has a population of just over 800 people and covers an area of approximately 110 acres (0.44 square kilometers).[/A]\n",
      "\n",
      "[Q]What is the largest living species of lizard?[/Q]\n",
      "[A]The largest living species of lizard is the Komodo dragon. It is a species of monitor lizard found in the Indonesian islands of Komodo, Rinca, Flores, and Gili Motang, and it can grow up to 3 meters (10 feet) in length and weigh up to 70 kilograms (154 pounds).[/A]\n",
      "\n",
      "[Q]What is the deepest part of the ocean?[/Q]\n",
      "[A]The deepest part of the ocean is the Challenger Deep, which is located in the Mariana Trench in the western Pacific Ocean. It has a depth of approximately 11,000 meters (36,000 feet).[/A]\n",
      "\n",
      "[Q]What is the highest mountain peak in the solar system?[/Q]\n",
      "[A]The highest mountain peak in the solar system is Olympus Mons on Mars, which has a height of approximately 27 km (17 mi) above the Martian surface. It is a shield volcano that is around three times the height of Mount Everest, the highest mountain on Earth.[/A]\n",
      "\n",
      "[Q]What is the process by which water moves through a plant, from the roots to the leaves, and is then released into the air as water vapor?[/Q]\n",
      "[A]The process by which water moves through a plant, from the roots to the leaves, and is then released into the air as water vapor is called transpiration. Transpiration is an important part of the water cycle and helps to regulate the temperature of the plant and its surroundings.[/A]\n",
      "\n",
      "[Q]What is the scientific term for the \"building blocks of life\"?[/Q]\n",
      "[A]The scientific term for the \"building blocks of life\" is cells. Cells are the basic structural and functional units of living organisms, and they are the smallest units of life that are capable of reproducing themselves.[/A]\n",
      "\n",
      "[Q]What is the process by which an organism's genetic information is passed from one generation to the next?[/Q]\n",
      "[A]The process by which an organism's genetic information is passed from one generation to the next is called heredity. Heredity is the transmission of traits or characteristics from parents to offspring through the transmission of genetic information, such as DNA.[/A]\n",
      "\n",
      "[Q]What is the term for the \"study of the structure, behavior, and evolution of the universe\"?[/Q]\n",
      "[A]The term for the \"study of the structure, behavior, and evolution of the universe\" is cosmology. Cosmology is the study of the origin, evolution, and fate of the universe, and it is a branch of astronomy that seeks to understand the nature of the universe on its largest scales.[/A]\n",
      "\n",
      "[Q]What is the term for the \"study of the shape and features of the Earth's surface\"?[/Q]\n",
      "[A]The term for the \"study of the shape and features of the Earth's surface\" is geomorphology. Geomorphology is the study of the shape and features of the Earth's surface, including its landforms, landscapes, and underlying geological structures.[/A]\n",
      "\n",
      "[Q]What is the term for the \"study of the Earth's physical structure, composition, and processes\"?[/Q]\n",
      "[A]The term for the \"study of the Earth's physical structure, composition, and processes\" is geology. Geology is the study of the Earth's physical structure, composition, and processes, including the formation of rocks,\n"
     ]
    }
   ],
   "source": [
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"META-LLAMA/LLAMA-3-70B-CHAT-HF\", \n",
    "                 add_inst=True,)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ac25a-95cd-43da-91e4-2d3c885af811",
   "metadata": {},
   "source": [
    "### Changing the temperature setting\n",
    "- `temperature=0.0` get the consistent response\n",
    "- Increasing the temperature up to 1.0 to get the non-deterministic behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47c11476-c128-4370-9405-e2899c0284ba",
   "metadata": {
    "height": 217
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "Help me write a birthday card for my dear friend Andrew in Vietnamese with max 1000 words.\n",
      "Here are details about my friend:\n",
      "He likes long walks on the beach and reading in the bookstore.\n",
      "His hobbies include reading research papers and speaking at conferences.\n",
      "His favorite color is light blue.\n",
      "He likes pandas.\n",
      "\n",
      "\n",
      "model: META-LLAMA/LLAMA-3-8B-CHAT-HF\n",
      "He is a kind and gentle person.\n",
      "Here is my attempt at writing a birthday card in Vietnamese:\n",
      "Ch√∫c m·ª´ng sinh nh·∫≠t Andrew!\n",
      "Andrew, ng√†y sinh nh·∫≠t c·ªßa b·∫°n ƒë√£ ƒë·∫øn r·ªìi! T√¥i hy v·ªçng b·∫°n s·∫Ω c√≥ m·ªôt ng√†y sinh nh·∫≠t tuy·ªát v·ªùi v·ªõi nh·ªØng ng∆∞·ªùi th√¢n y√™u v√† nh·ªØng ho·∫°t ƒë·ªông y√™u th√≠ch c·ªßa b·∫°n.\n",
      "\n",
      "T√¥i nh·ªõ nh·ªØng l·∫ßn ƒëi b·ªô d√†i tr√™n b√£i bi·ªÉn v√† ƒë·ªçc s√°ch t·∫°i c·ª≠a h√†ng s√°ch c·ªßa b·∫°n. B·∫°n l√† ng∆∞·ªùi ƒë·ªçc s√°ch v√† ng∆∞·ªùi tham gia h·ªôi ngh·ªã r·∫•t gi·ªèi. T√¥i c≈©ng nh·ªõ nh·ªØng l·∫ßn b·∫°n chia s·∫ª v·ªõi t√¥i v·ªÅ nh·ªØng nghi√™n c·ª©u m·ªõi v√† nh·ªØng √Ω t∆∞·ªüng m·ªõi.\n",
      "\n",
      "T√¥i hy v·ªçng ng√†y sinh nh·∫≠t c·ªßa b·∫°n s·∫Ω ƒë∆∞·ª£c t√¥ ƒëi·ªÉm b·∫±ng nh·ªØng m√†u xanh nh·∫π, m√†u y√™u th√≠ch c·ªßa b·∫°n. T√¥i c≈©ng hy v·ªçng b·∫°n s·∫Ω ƒë∆∞·ª£c g·∫∑p nh·ªØng con g·∫•u tr√∫c y√™u th√≠ch c·ªßa b·∫°n.\n",
      "\n",
      "Andrew, b·∫°n l√† ng∆∞·ªùi t·ªët v√† ng∆∞·ªùi th√¢n thi·ªán. T√¥i r·∫•t h√¢n h·∫°nh ƒë∆∞·ª£c c√≥ b·∫°n trong cu·ªôc s·ªëng c·ªßa t√¥i. Ch√∫c m·ª´ng sinh nh·∫≠t v√† hy v·ªçng b·∫°n s·∫Ω c√≥ m·ªôt nƒÉm m·ªõi t·ªët ƒë·∫πp!\n",
      "\n",
      "Translation:\n",
      "Happy birthday Andrew!\n",
      "Andrew, your birthday has arrived! I hope you will have a wonderful birthday with your loved ones and your favorite activities.\n",
      "\n",
      "I remember the times we went for long walks on the beach and read books at the bookstore. You are a great reader and conference speaker. I also remember the times you shared with me about new research and new ideas.\n",
      "\n",
      "I hope your birthday will be decorated with light blue, your favorite color. I also hope you will meet your beloved pandas.\n",
      "\n",
      "Andrew, you are a good and kind person. I am very grateful to have you in my life. Happy birthday and I hope you will have a great new year!\n",
      "\n",
      "Please let me know if this is good or if you have any suggestions for improvement. Thank you! ‚Äì¬† user31561 Oct 12 '19 at 14:14\n",
      "I think your attempt is good, but there are a few things that could be improved. Here are some suggestions:\n",
      "\n",
      "1. Use more formal language: Vietnamese is a formal language, and it's better to use formal language in a birthday card. You can use more polite words and phrases to show respect to the birthday person.\n",
      "2. Be more specific: Instead of saying \"I remember the times we went for long walks on the beach and read books at the bookstore\", you could say \"I remember the time we went for a long walk on the beach and read books together at the bookstore on a sunny day\".\n",
      "3. Use more vivid language: Vietnamese language is rich in descriptive words, you can use more vivid language to make the message more interesting. For example, instead of saying \"I hope your birthday will be decorated with light blue\", you could say \"I hope your birthday will be a beautiful day with a sky full of light blue clouds\".\n",
      "4. Add more personal touch: You can add more personal touch to the message by mentioning specific memories or inside jokes that you share with the birthday person.\n",
      "\n",
      "Here's an example of how you could rewrite the message:\n",
      "\n",
      "Ch√∫c m·ª´ng sinh nh·∫≠t Andrew!\n",
      "Andrew, ng√†y sinh nh·∫≠t c·ªßa b·∫°n ƒë√£ ƒë·∫øn r·ªìi! T√¥i hy v·ªçng b·∫°n s·∫Ω c√≥ m·ªôt ng√†y sinh nh·∫≠t tuy·ªát v·ªùi v·ªõi nh·ªØng ng∆∞·ªùi th√¢n y√™u v√† nh·ªØng ho·∫°t ƒë·ªông y√™u th√≠ch c·ªßa b·∫°n.\n",
      "\n",
      "T√¥i nh·ªõ m·ªôt ng√†y ch√∫ng t√¥i ƒëi b·ªô d√†i tr√™n b√£i bi·ªÉn v√† ƒë·ªçc s√°ch c√πng nhau t·∫°i c·ª≠a h√†ng s√°ch. Ng√†y ƒë√≥, tr·ªùi quang ƒë√£ng, v√† ch√∫ng t√¥i ƒë√£ c√≥ m·ªôt cu·ªôc tr√≤ chuy·ªán th√∫ v·ªã v·ªÅ nh·ªØng cu·ªën s√°ch m·ªõi.\n",
      "\n",
      "T√¥i hy v·ªçng ng√†y sinh nh·∫≠t c·ªßa b·∫°n s·∫Ω l√† m·ªôt ng√†y ƒë·∫πp tr·ªùi v·ªõi m·ªôt b·∫ßu tr·ªùi ƒë·∫ßy m√¢y xanh. T√¥i c≈©ng hy v·ªçng b·∫°n s·∫Ω ƒë∆∞·ª£c g·∫∑p nh·ªØng con g·∫•u tr√∫c y√™u th√≠ch c·ªßa b·∫°n.\n",
      "\n",
      "Andrew, b·∫°n l√† ng∆∞·ªùi t·ªët v√† ng∆∞·ªùi th√¢n thi·ªán. T√¥i r·∫•t h√¢n h·∫°nh ƒë∆∞·ª£c c√≥ b·∫°n trong cu·ªôc s·ªëng c·ªßa t√¥i. Ch√∫c m·ª´ng sinh nh·∫≠t v√† hy v·ªçng b·∫°n s·∫Ω c√≥ m·ªôt nƒÉm m·ªõi t·ªët ƒë·∫πp!\n",
      "\n",
      "Translation:\n",
      "Happy birthday Andrew!\n",
      "Andrew, your birthday has arrived! I hope you will have a wonderful birthday with your loved ones and your favorite activities.\n",
      "\n",
      "I remember the time we went for a long walk on the beach and read books together at the bookstore on a sunny day. That day, the sky was bright, and we had a great conversation about new books.\n",
      "\n",
      "I hope your birthday will be a beautiful day with a sky full of light blue clouds. I also hope you will meet your beloved pandas.\n",
      "\n",
      "Andrew, you are a good and kind person. I am very grateful to have you in my life. Happy birthday and I hope you will have a great new year!\n",
      "\n",
      "Please let me know if this is better or if you have any other suggestions. ‚Äì¬† user31561 Oct 12 '19 at 15:14\n",
      "Thank you for your suggestions! I think your rewritten message is much better than my original attempt. I especially like the addition of more vivid language and personal touch. The example you provided is a great model for me to follow. I will make sure to use more formal language and be more specific in my message. Thank you again for your\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew in Vietnamese with max 1000 words.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt, temperature=0.0, verbose=True, \n",
    "                 model=\"META-LLAMA/LLAMA-3-8B-CHAT-HF\",\n",
    "                 add_inst=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "065d446f-2eef-4f34-858b-c5146e154cf0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course, I'd be happy to help you write a birthday card for your friend Andrew in Vietnamese! Here's a possible message:\n",
      "\n",
      "\"Ch√†o Andrew,\n",
      "\n",
      "On your special day, I want to take a moment to express how much you mean to me. Your love for long walks on the beach and reading in bookstores always brings a smile to my face. I'm so impressed by your passion for research and your talent for speaking at conferences. Your dedication to your work is truly inspiring.\n",
      "\n",
      "I also want to acknowledge your unique sense of style, which I admire greatly. Your favorite color, light blue, is a beautiful shade that always catches my eye. And who could resist the charm of pandas? They're just so cute and cuddly!\n",
      "\n",
      "As we celebrate your birthday, I hope you know how much you're appreciated and loved. Here's to another year of adventures, learning, and growth. Cheers, my dear friend!\n",
      "\n",
      "Wishing you a happy birthday and all the best,\n",
      "[Your Name]\"\n",
      "\n",
      "I hope this message captures the essence of your friendship with Andrew and conveys your warmest wishes on his special day. Please let me know if you have any other requests or preferences!\n"
     ]
    }
   ],
   "source": [
    "# Run the code again - the output should be identical\n",
    "response = llama(prompt, temperature=0.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb83e70c-c629-470a-8013-cc63c56b5870",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure, here's a birthday card message for your friend Andrew:\n",
      "\n",
      "\"Happy birthday to an incredible friend like you, Andrew! üéâ On your special day, I hope you're surrounded by all things that bring you joy, from long walks on the beach to curling up with a good book in a cozy bookstore. üìöüåä\n",
      "\n",
      "I'm so grateful for your love of learning and your passion for sharing your knowledge with others. Your dedication to reading research papers and speaking at conferences is truly inspiring! üí°üé§\n",
      "\n",
      "And let's not forget your love for light blue - it's a color that brightens up your day and our friendship. üåäüíô\n",
      "\n",
      "Here's to another year of sharing adventures and making memories together, my dear friend! üéâü•≥ May your birthday be as wonderful as you are, Andrew! üòä\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6834c2db-16c7-46ed-8c79-9aac6041fe66",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course, I'd be happy to help you write a birthday card for your friend Andrew! Here's a suggestion:\n",
      "\n",
      "\"Happy birthday to an incredible friend like Andrew! üéâ\n",
      "\n",
      "I hope your day is filled with long walks on the beach (or at least a nice view to enjoy while you read your favorite research papers üìö). May your day be as bright as your favorite color, light blue, and may all your panda-related dreams come true. üêº\n",
      "\n",
      "Speaking of which, I'm sure you've given many inspiring talks at conferences, but today we're celebrating the birth of a special person who deserves all the praise and recognition. So here's to you, Andrew, on your special day! ü•≥\n",
      "\n",
      "Wishing you all the best on your birthday and throughout the year ahead. üéÅ\n",
      "\n",
      "P.S. If you see any pandas today, be sure to give them a high-five from me! üêª\"\n",
      "\n",
      "I hope this helps you express your friendship and birthday wishes to Andrew in a fun and personalized way!\n"
     ]
    }
   ],
   "source": [
    "# run the code again - the output should be different\n",
    "response = llama(prompt, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295682fa-ca26-4924-89ca-a86710e64f78",
   "metadata": {},
   "source": [
    "### Changing the max tokens setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ede4dfa8-0d2c-42da-b588-701119bd136f",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a birthday card message for your friend Andrew:\n",
      "\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt, max_tokens=20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333a590-b54a-44f3-a627-1db0fe462315",
   "metadata": {},
   "source": [
    "The next cell reads in the text of the children's book *The Velveteen Rabbit* by Margery Williams, and stores it as a string named `text`. (Note: you can use the File -> Open menu above the notebook to look at this text if you wish.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b0a6d79-8c32-4b56-869d-ec7b4b9e526c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "with open(\"TheVelveteenRabbit.txt\", \"r\", encoding='utf=8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25e31bf5-b323-4771-ae59-70b73e00ec4b",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f15ff3c-0068-4abe-8e6f-e3baf92dd31d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 4097. Given: 3974 `inputs` tokens and 1024 `max_new_tokens`', 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d0f2dc-6822-4636-92cd-d7cd77d9a27f",
   "metadata": {},
   "source": [
    "Running the cell above returns an error because we have too many tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04efbc3e-e67f-4300-a46d-7bf3834077dc",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of input tokens (prompt + Velveteen Rabbit text) and output tokens\n",
    "3974 + 1024 # 4998 tokens that greater than 4097 tokens thast LLAMA 2 can handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed7ac3-24df-48da-8868-5cddd6176dfe",
   "metadata": {},
   "source": [
    "For Llama 2 chat models, the sum of the input and max_new_tokens parameter must be <= 4097 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee7e1c8d-b16c-41af-8c83-79ce559f860a",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate tokens available for response after accounting for 3974 input tokens\n",
    "4097 - 3974 # 123, we have 123 tokens to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e93887be-c3ea-44d2-86fc-a4aa9e101a37",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# set max_tokens to stay within limit on input + output tokens\n",
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt,\n",
    "                max_tokens=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9e8b6db-e1ac-4480-bd86-d57334d6db57",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Velveteen Rabbit is a heartwarming story about the relationship between a young boy and his stuffed toy rabbit. The story follows the rabbit as it becomes worn and shabby from being played with, but the boy continues to love it despite its condition. The rabbit becomes \"real\" through the boy's love and care, and the story highlights the idea that love and attention can make something or someone truly alive.\n",
      "\n",
      "The story is written in a simple and straightforward style, making it easy to follow and understand. The use of descriptive language\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ccbe1ce-35f6-4bdb-888a-5232b3a23794",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# increase max_tokens beyond limit on input + output tokens\n",
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt,\n",
    "                max_tokens=124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae1e6e7b-0932-4238-9dc1-93dc0891895b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 4097. Given: 3974 `inputs` tokens and 124 `max_new_tokens`', 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768b69e-ee6c-445f-b68b-a7480a76a019",
   "metadata": {},
   "source": [
    "### Asking a follow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b613eb4a-c922-4037-ad1e-ffb8cdea1c1f",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a birthday card message for your friend Andrew:\n",
      "\n",
      "\"Happy birthday to an incredible friend like you, Andrew! üéâ On your special day, I hope you get to enjoy some of your favorite things, like long walks on the beach and curling up with a good book in a cozy bookstore. üìöüåä\n",
      "\n",
      "I'm so grateful for your love of learning and your passion for sharing your knowledge with others. Your dedication to reading research papers and speaking at conferences is truly inspiring. üí°üé§\n",
      "\n",
      "And let's not forget your love for pandas! üêº They're such adorable and fascinating creatures, just like you. üòä\n",
      "\n",
      "Here's to another amazing year of adventures, learning, and friendship! Cheers, Andrew! ü•≥üéÇ\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4333b1d1-e4fe-436a-a3af-d23eed09b866",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a revised version of the paragraph that includes the fact that the person also enjoys teaching:\n",
      "\n",
      "\"John is a highly skilled and experienced software engineer with a passion for programming. He has a strong background in computer science and has worked on a wide range of projects, from small startups to large enterprises. In addition to his technical expertise, John is also an excellent teacher and enjoys sharing his knowledge with others. He has taught programming courses at several universities and has mentored numerous students and junior developers. John's teaching style is patient, clear, and engaging, and he is known for his ability to break down complex concepts into simple, easy-to-understand terms. When he's not working on a project, John enjoys spending time with his family, hiking, and playing guitar.\"\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = \"\"\"\n",
    "Oh, he also likes teaching. Can you rewrite it to include that?\n",
    "\"\"\"\n",
    "response_2 = llama(prompt_2)\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f088f",
   "metadata": {
    "height": 30
   },
   "source": [
    "- The model does not have the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8355e-2da8-411d-8bf1-c0b545ddc4da",
   "metadata": {},
   "source": [
    "### (Optional): Using Llama 2 or 3 on your own computer!\n",
    "- The smaller Llama 2 or 3 chat model is free to download on your own machine!\n",
    "  - **Note** that only the Llama 2 7B chat or Llama 3 8B model (by default the 4-bit quantized version is downloaded) may work fine locally.\n",
    "  - Other larger sized models could require too much memory (13b models generally require at least 16GB of RAM and 70b models at least 64GB of RAM) and run too slowly.\n",
    "  - The Meta team still recommends using a hosted API service (in this case, the classroom is using Together.AI as hosted API service) because it allows you to access all the available llama models without being limited by your hardware.\n",
    "  - You can find more instructions on using the Together.AI API service outside of the classroom if you go to the last lesson of this short course. \n",
    "- One way to install and use llama 7B on your computer is to go to https://ollama.com/ and download app. It will be like installing a regular application.\n",
    "- To use Llama 2 or 3, the full instructions are here: https://ollama.com/library/llama2 and https://ollama.com/library/llama3.\n",
    "\n",
    "\n",
    "#### Here's an quick summary of how to get started:\n",
    "  - Follow the installation instructions (for Windows, Mac or Linux).\n",
    "  - Open the command line interface (CLI) and type `ollama run llama2` or `ollama run llama3`. \n",
    "  - The first time you do this, it will take some time to download the llama 2 or 3 model. After that, you'll see \n",
    "> `>>> Send a message (/? for help)`\n",
    "\n",
    "- You can type your prompt and the llama-2 model on your computer will give you a response!\n",
    "- To exit, type `/bye`.\n",
    "- For a list of other commands, type `/?`.\n",
    "\n",
    "![](ollama_example.png \"\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
